[{"faithfulness": 0.24233333333333335, "answer_relevancy": 0.7891260288118983, "answer_similarity": 0.8724913213906453, "context_recall": 0.5818181818181818, "context_precision": 0.109999999989, "dataset": "cais/mmlu"}, {"faithfulness": 0.35, "answer_relevancy": 0.7287743772148643, "answer_similarity": 0.7742705342115229, "context_recall": 0.4393333333333333, "context_precision": 0.21999999997799996, "dataset": "natural_questions"}, {"faithfulness": 0.345, "answer_relevancy": 0.7211926494295692, "answer_similarity": 0.7742721770569263, "context_recall": 0.436, "context_precision": 0.21999999997799996, "dataset": "natural_questions"}, {"faithfulness": 0.41666666666666663, "answer_relevancy": 0.8460790066366235, "answer_similarity": 0.8862564046166932, "context_recall": 0.6133333333333333, "context_precision": 0.189999999981, "dataset": "mandarjoshi/trivia_qa"}, {"faithfulness": 0.11616161616161616, "answer_relevancy": 0.7426989222916629, "answer_similarity": 0.8164095974106347, "context_recall": 0.215, "context_precision": 0.029999999997, "dataset": "hotpot_qa"}, {"faithfulness": 0.11447811447811447, "answer_relevancy": 0.7421290442159001, "answer_similarity": 0.8164462101927001, "context_recall": 0.225, "context_precision": 0.029999999997, "dataset": "hotpot_qa"}]