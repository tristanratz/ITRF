{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset, load_dataset\n",
    "from qdrant_client import models, QdrantClient\n",
    "from langchain.embeddings import HuggingFaceBgeEmbeddings\n",
    "from langchain.vectorstores import Qdrant\n",
    "import time\n",
    "from datetime import timedelta\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from matplotlib import pyplot as plt\n",
    "from dotenv import load_dotenv\n",
    "import numpy as np\n",
    "\n",
    "import sys\n",
    "import os\n",
    "sys.path.append(os.path.abspath('../'))\n",
    "\n",
    "from model.llm import LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1ae16d9099c4b99878d9af12bad8f44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "llm = LLM(size=7, quantized=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 10\n",
    "itrf_dataset_buffer = []\n",
    "k=10\n",
    "options_enabled = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview of the dataset attributes\n",
    "- Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_name = \"retriever\"\n",
    "\n",
    "#tokenizer = LlamaTokenizer.from_pretrained(\"../models/llama7b\", device_map='cuda')\n",
    "embedding = HuggingFaceBgeEmbeddings(model_name=\"../models/retriever/bge-base-en-v1.5\", model_kwargs={\"device\": \"cuda:1\"})\n",
    "\n",
    "# Create the retriever\n",
    "client = QdrantClient(url=\"http://localhost:6333\")\n",
    "db = Qdrant(client, \n",
    "            collection_name=col_name,\n",
    "            embeddings=embedding,\n",
    "            )\n",
    "\n",
    "seed = 4048\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    \"\"\"Compute softmax values for each sets of scores in x.\"\"\"\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum()\n",
    "\n",
    "def search(query: str, k: int = 3):\n",
    "    success = False\n",
    "    while not success:\n",
    "        try:\n",
    "            results = db.similarity_search_with_score(query, k=k)\n",
    "            if results:\n",
    "                success = True \n",
    "        except:\n",
    "            print(f\"Error with example {query}, retrying in 0.2s\")\n",
    "            time.sleep(0.2)\n",
    "    return results\n",
    "\n",
    "# This function creates an example with the query and the prediction and the top k results\n",
    "def make_example(query: str, ground_truth:str, dataset_name:str, context = None, example_id = None, k: int = 3, split = \"llm\", retrieval = True, task=\"\", domain=\"\"):\n",
    "    contexts = []\n",
    "    if retrieval:\n",
    "        # Search for the query\n",
    "        results = search(query, k=k)\n",
    "\n",
    "        # Get the softmax of the scores\n",
    "        retriever_softmax = softmax([result[1] for result in results])\n",
    "        context_texts = [llm.format_prompt(query, result[0].page_content) for result in results]\n",
    "        llm_scores = llm.to_tokens_and_logprobs(context_texts, [ground_truth] * k)[1]\n",
    "        llm_softmax = softmax(llm_scores)\n",
    "\n",
    "        # Get the text of the results\n",
    "        contexts = [{\n",
    "            \"text\": result[0].page_content, \n",
    "            \"src\": result[0].metadata[\"src\"] if \"src\" in result[0].metadata.keys() else \"unknown\", \n",
    "            \"id\": result[0].metadata[\"id\"] if \"id\" in result[0].metadata.keys() else result[0].metadata[\"title\"],\n",
    "            \"retriever_score\": result[1],\n",
    "            \"llm_score\": lscore,\n",
    "            \"retriever_softmax\": rsoft, \n",
    "            \"llm_softmax\": lsoft, \n",
    "            \"llm_weighted_softmax\": rsoft * lsoft, \n",
    "            \"original_context\": False } \n",
    "            for result, rsoft, lsoft, lscore in zip(results, retriever_softmax, llm_softmax, llm_scores)]\n",
    "    \n",
    "    # Add the original context\n",
    "    if context:\n",
    "        contexts.append({\n",
    "            \"text\": context, \n",
    "            \"src\": dataset_name, \n",
    "            \"id\": str(example_id), \n",
    "            \"original_context\": True\n",
    "            })\n",
    "\n",
    "    return { \n",
    "        \"split\": split, \n",
    "        \"query\": query, \n",
    "        \"ground_truth\": ground_truth, \n",
    "        \"contexts\": contexts,\n",
    "        \"src\": dataset_name, \n",
    "        \"id\": str(example_id),\n",
    "        \"task\": task,\n",
    "        \"domain\": domain, \n",
    "        }\n",
    "\n",
    "itrf_dataset_buffer = []\n",
    "itrf = DataFrame(columns=[\"split\", \"query\", \"prediction\", \"context\", \"src\", \"id\", \"context_src\", \"context_id\", \"original_context\", \"task\", \"domain\"])\n",
    "\n",
    "def make_examples(query: str, prediction:str, dataset_name:str, context = None, example_id = None, k: int = 3, retrieval = True, task=\"\", domain=\"\"):\n",
    "    examples = []\n",
    "    ex = make_example(query, prediction, dataset_name, context, example_id, k, retrieval=retrieval, task=task, domain=domain)\n",
    "    for c in ex[\"contexts\"]:\n",
    "        examples.append({ \n",
    "            \"split\": ex[\"split\"], \n",
    "            \"query\": ex[\"query\"], \n",
    "            \"ground_truth\": ex[\"ground_truth\"], \n",
    "\n",
    "            \"retriever_score\": c[\"retriever_score\"],\n",
    "            \"llm_score\": c[\"llm_score\"],\n",
    "            \"retriever_softmax\": c[\"retriever_softmax\"], \n",
    "            \"llm_softmax\": c[\"llm_softmax\"], \n",
    "            \"llm_weighted_softmax\": c[\"llm_weighted_softmax\"], \n",
    "\n",
    "            \"context\": c[\"text\"], \n",
    "            \"src\": ex[\"src\"], \n",
    "            \"id\": str(ex[\"id\"]), \n",
    "            \"context_src\": c[\"src\"], \n",
    "            \"context_id\": str(c[\"id\"]), \n",
    "            \"original_context\": c[\"original_context\"],\n",
    "            \"task\": task,\n",
    "            \"domain\": domain,\n",
    "            })\n",
    "    return examples\n",
    "\n",
    "def save_example(i, start, last_time, example, dname, force=False):\n",
    "    save_examples(i, start, last_time, [example], dname, force=force)\n",
    "\n",
    "def save_examples(i, start, last_time, examples, dname, force=False):\n",
    "    global itrf_dataset_buffer\n",
    "    global itrf\n",
    "    # Save the dataset to a file\n",
    "    itrf_dataset_buffer.extend(examples)\n",
    "    \n",
    "    if i % 100 == 0 or force:\n",
    "        current_time = time.time()\n",
    "        print(f\"Processed {i} {dname} examples, time: {str(timedelta(seconds=(last_time - start)))}, last 100 in {str(timedelta(seconds=(current_time - last_time)))}\")\n",
    "        last_time = current_time\n",
    "        if len(itrf_dataset_buffer) > 0:\n",
    "            if itrf.empty:\n",
    "                itrf = DataFrame(itrf_dataset_buffer)\n",
    "            else:\n",
    "                df = DataFrame(itrf_dataset_buffer)\n",
    "                itrf = pd.concat([itrf, df])\n",
    "            itrf_dataset_buffer.clear()\n",
    "        itrf.to_parquet(\"../data/dataset/itrf_dataset_reranker.parquet\")\n",
    "        itrf.to_csv(\"../data/dataset/itrf_dataset_reranker.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Open domain questioning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_openqa = [\"tau/commonsense_qa\", \"math_qa\", \"web_questions\", \"wiki_qa\", \"yahoo_answers_qa\", \"freebase_qa\", \"ms_marco\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tau/commonsense_qa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def make_examples(query: str, prediction:str, dataset_name:str, context = None, example_id = None, k: int = 3, retrieval = True)\n",
    "dname = datasets_openqa[0]\n",
    "dataset = load_dataset(dname, split=\"train\")\n",
    "shuffled = iter(dataset.shuffle(seed=seed))\n",
    "start = time.time()\n",
    "last_time = start\n",
    "for i in range(n):\n",
    "    example = next(shuffled)\n",
    "\n",
    "    options = \"\"\n",
    "    if options_enabled:\n",
    "        options = \"\\n Options: \"\n",
    "    answer = -1\n",
    "    for idx, o in enumerate(example[\"choices\"][\"label\"]):\n",
    "        if options_enabled:\n",
    "            options += f\"{o}: {example['choices']['text'][idx]}, \"\n",
    "        if example[\"answerKey\"] == o:\n",
    "            answer = idx\n",
    "    if options_enabled: \n",
    "        options += \"\\n\"\n",
    "\n",
    "    query = example[\"question\"] + options\n",
    "    if options_enabled:\n",
    "        prediction = f\"{example['answerKey']}) {example['choices']['text'][answer]}\"\n",
    "    else:\n",
    "        prediction =  f\"{example['choices']['text'][answer]}\"\n",
    "    example_id = example[\"id\"] + \"_\" + example[\"question_concept\"]\n",
    "    examples = make_examples(query, prediction, dname, example_id=example_id, k=k, retrieval=True, task=\"mc\", domain=\"openqa\")\n",
    "    \n",
    "    save_examples(i, start, last_time, examples, dname)\n",
    "\n",
    "itrf_dataset_buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "90"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(itrf_dataset_buffer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FreebaseQA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'FreebaseQA-train-234'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dname = datasets_openqa[5]\n",
    "dataset = load_dataset(dname, split=\"train\")\n",
    "\n",
    "dataset[234][\"Question-ID\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dname = datasets_openqa[5]\n",
    "dataset = load_dataset(dname, split=\"train\")\n",
    "shuffled = iter(dataset.shuffle(seed=2024))\n",
    "start = time.time()\n",
    "last_time = start\n",
    "for i in range(n):\n",
    "    example = next(shuffled)\n",
    "\n",
    "    query = example[\"RawQuestion\"]\n",
    "    prediction =  example['Parses'][\"Answers\"][0][\"AnswersName\"][0][0]\n",
    "    example_id = example[\"Question-ID\"]\n",
    "    examples = make_examples(query, prediction, dname, example_id=example_id, k=k, retrieval=True, task=\"qa\", domain=\"openqa\")\n",
    "    \n",
    "    save_examples(i, start, last_time, examples, dname)\n",
    "\n",
    "itrf_dataset_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MS Marco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<s>Background: The difference between a vegetable and a fruit is that vegetables are the edible portions of a plant, such as the leaves, stem, roots, tubers, bulbs and flowers, while a fruit is the mature ovary of a plant. Many plants that are considered fruits are botanically vegetables.\n",
      "Some plants commonly known as vegetables, such as tomatoes, squash, pepper and eggplant, are botanically fruits. Fruits don't have to be sweet. Fruits provide protection for seeds in many plants and aid in the distribution of seeds.\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: If by this you mean what fruits are customarily called vegetables, two of the most common are the tomato and the cucumber .\n",
      "A vegetable is any edible part of a plant, and can include roots, tubers, stems, leaves, flowers, and fruits. A fruit is the part of a seed-bearing plant that contains the seeds. Foods like tomatoes, peppers, squash, cucumbers, and so forth, are vegetables that are also fruits.\n",
      "What is the difference between fruits and vegetables when all vegetables have seeds Example green beans peas corn?\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: The \"common sense\" (or culinary) answer is that a fruit is something you would put in a fruit bowl, while a vegetable is any (non-sweet) part of a plant that you'd be able to serve in a dish.. The botanically correct answer, however, might surprise you, as many things you'd call vegetables are in fact fruits, such as your examples as well as tomatoes, cucumbers etc. The (botanical) fruit of a plant is the seed-carrying ovary. If it is high in fruit sugar, or fructose, it tastes sweet and is subsequently called a \"fruit\" in the culinary sense. \"Fruits\" that\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: “vegetable” is actually not a scientific term and simply refers to the edible part of the plant: roots/tubers, stems, leaves, etc a fruit is the seed-containing part of a plant if you want to get all botany-nerdy, a fruit is the fleshy or dry ripened ovary of a plant we often assume that . Fresh, filling and heart-healthy, fruits and vegetables are an important part of your overall healthy eating plan they are high in vitamins, minerals and fiber and low in fat and calories eating a variety of fruits and vegetables may help you control your weight and your\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: the fruit and vegetable are mutually exclusive. Fruit has a precise meaning, being a part that developed from the ovary of a flowering plant. This is considerably different from the words culinary meaning, while peaches, plums, and oranges are fruit in both senses, many items commonly called vegetables, such as eggplants, bell peppers, and tomatoes, are botanically fruits. The question of whether the tomato is a fruit or a vegetable found its way into the United States Supreme Court in 1893\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: Fruits and vegetables are nutritional foods grown in farms and orchards. Some fruits are apples, bananas, strawberries,and grapes. Some vegetables are tomatoes, spinach,and carrots.. Fruit: . - Apples. - Oranges. - Pineapples. - Pears. - Bananas. - Kiwi. - Tomatoes. . Vegetables: . - Peas. - Cauliflower. - Sprouts. - Carrots. - Leaks. - Cucumber. - Cabbage. . There are many many fruit and vegetables out there. All you have to do is look them up. :) . Difference between fruit and veg:. ( A fruit is actually the sweet, ripened ovary or ovaries of a seed-bearing plant. A vegetable,\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: Yes, it’s true. Many “vegetables” have been parading around as fruits, and we’re here to unveil their secret. But before we unmask the produce perpetrators, let’s talk about what actually makes a fruit a fruit and a vegetable a vegetable.\n",
      "Fruits have seeds and are a product of a flowering plant, like trees, bushes or vines. Hence, banana tree, strawberry bush, and grapevine.\n",
      "Vegetables are generally roots, stems, and leaves. For example, carrots and potatoes are actually roots that are pulled up from underground, and cabbage and spinach are leaves.\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: Fruits and vegetables are plants that we eat. Since we are omnivores, we eat both plants and meat. The meat that we eat are cows, pigs, sheep, chicken, duck and sea food. Fruits and vegetables grow in either trees or the ground. Fruits and vegetables are in the same food group. So above, it says fruits and vegetables are plants that grow. The difference between a fruit and a vegetable is that fruits have seeds and vegetables don't. Bananas may appear to have no seeds but they do. Some people might also think that tomatoes, cucumbers and kiwi are vegetables\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: Fruits and vegetables preschool and kindergarten activities our fruit and vegetable crafts, activities, games, and other resources present an exciting way for you and your children to learn about these healthy foods. The exact definition of vegetable may vary simply because of the many parts of a plant consumed as food worldwide – roots, stems, leaves, flowers, fruits, and seeds. Try any of these fruit and vegetable recipes today and create a hearty meal that is certified delicious, healthy, and easy to prepare.\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "<s>Background: but they are completely a fruit because of their seeds. Also, vegetables are either the root part or the actual bulk of the plant that we eat, while fruits are the seed parts of the plant that are produced from flowers. When we pick a vegetable, usually the entire plant is taken out, but when we pick fruit, the plant lasts to produce more fruit. This hold true for all the above stated fruits.\n",
      "\n",
      "[INST]what is a fruit and what is a vegetable[/INST][ANS] A fruit is the mature ovary of a seed plant, usually developed from a flower. A vegetable is a plant or that part of a plant which is edible, and does not necessarily have a role in the plant's reproductive cycle.\n",
      "Processed 0 ms_marco examples, time: 0:00:00, last 100 in 0:00:01.037192\n",
      "<s>Background: Fortified soy products are often fortified with both vitamin D and calcium. Fortified Tofu can provide up to 157IU (39% DV) of vitamin D per 100 gram serving, or 44IU (11% DV) per ounce. Fortified Soy Milk can provide up to 49IU (12% DV) of vitamin D per 100 gram serving, 119IU (30% DV) per cup. Amounts of vitamin D vary widely between products, so be sure to check nutrition facts for vitamin D content.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: Vegans and vegetarians are at a higher risk of vitamin D deficiency because of their limited intake of dairy, meat, and fish. If you have a plant-based diet, make sure to include fortified tofu. Be sure to pay attention to the packaging the next time you go grocery shopping because not all tofu is fortified with vitamin D. One serving of fortified tofu contains 101 UI of vitamin D. Tofu is more versatile than you think. You can bake it, grill it, or add to a delicious stir-fry.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: Soy milk is a good source of protein, and most soy foods are fortified with calcium, riboflavin, and vitamins A, D, and B12, McClinton says.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: Very few foods are naturally rich in Vitamin D. Fortified foods are the major dietary sources of vitamin D, and these include milk, soy milk, cereal grains, margarine, bread and pastries. It is important for individuals with limited sun exposure (from whatever cause or for whatever reason) to include a food source of vitamin D in their diet.\n",
      "In Australia, there is mandatory fortification of table edible oil spreads (eg low-fat spreads) and table margarine, and voluntary fortification of modified and skim milks, powdered milk, yoghurts, table confections and cheese.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: I'm a Registered Dietitian and I am concerned with the nutrition claims on the website. Soy milk is fortified with Vitamin D2, which is not as easily absorbed as Vitamin D3. Soy milk...Read complete review\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: Essentially what you are looking for are foods that have been fortified with vitamin D by manufacturers because it is not a common natural ingredient in food. The most likely way of taking enough vitamin D is via supplements as it is difficult to recommend exposure to sun as that could increase chances of skin cancer and isn’t always feasible for people with full time jobs.\n",
      "Vitamin D then is made by the body and plays a key role in aiding the absorption of magnesium, phosphate, calcium, and zinc.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: What it does: Vitamin D helps with absorption of calcium to keep your bones healthy, and some studies have linked it to mood and immune function, notes Lopez. Fatty fish like salmon and tuna are among the best sources of D along with fortified milk, yogurt, and eggs; plant-based sources include mushrooms and fortified OJ.\n",
      "Why vegans need it: “Most people have trouble getting enough vitamin D whether they’re vegan or not,” says Lopez. But how much D doctors think the average person needs, however, is changing. “We’re learning and trying to get a better handle on it,” she adds.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: There are few foods that naturally contain vitamin D, so fortified foods provide most of it in the American diet. The following foods contain vitamin D:\n",
      "Mushrooms provide some vitamin D (some mushrooms have the vitamin D content boosted by exposing these mushrooms to ultraviolet light)\n",
      "Almost all of the U.S. milk supply is fortified with 400 IU of vitamin D per quart. But foods made from milk, like cheese and ice cream, are usually not fortified\n",
      "Vitamin D is added to many breakfast cereals and to some brands of orange juice, yogurt, margarine, and soy beverages; check the labels\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: In addition to being an excellent source of calcium, a cup of milk offers between 115 and 124 units of vitamin D. Make sure you check the label of your favourite brand for the exact amount. Fortified plant-based milks, such as soy, also contain vitamin D. Enjoy a cold 8 oz. glass of your preferred fortified milk straight up, blend it into a smoothie, or use it to whip up your choice of coffee drink.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n",
      "<s>Background: I'm a Registered Dietitian and I am concerned with the nutrition claims on the website. Soy milk is fortified with Vitamin D2, which is not as easily absorbed as Vitamin D3. Soy milk does not have 50% more calcium than dairy milk either as you can see in the nutrition facts table on this website. It's still a good choice nutritionally but the health claims are being exaggerated.\n",
      "\n",
      "[INST]are fortified soy-based food good source of vitamin d[/INST][ANS] Yes\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "1 is not in list",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 13\u001b[0m\n\u001b[1;32m     10\u001b[0m prediction \u001b[38;5;241m=\u001b[39m  example[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     11\u001b[0m example_id \u001b[38;5;241m=\u001b[39m dname \u001b[38;5;241m+\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_type\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mquery_id\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 13\u001b[0m context_id \u001b[38;5;241m=\u001b[39m \u001b[43mexample\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpassages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mis_selected\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     14\u001b[0m context \u001b[38;5;241m=\u001b[39m example[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpassage_text\u001b[39m\u001b[38;5;124m\"\u001b[39m][context_id]\n\u001b[1;32m     16\u001b[0m examples \u001b[38;5;241m=\u001b[39m make_examples(query, prediction, dname, example_id\u001b[38;5;241m=\u001b[39mexample_id, k\u001b[38;5;241m=\u001b[39mk, retrieval\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, task\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mqa\u001b[39m\u001b[38;5;124m\"\u001b[39m, domain\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mopenqa\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: 1 is not in list"
     ]
    }
   ],
   "source": [
    "dname = datasets_openqa[6]\n",
    "dataset = load_dataset(dname, 'v2.1', split=\"train\")\n",
    "shuffled = iter(dataset.shuffle(seed=2024))\n",
    "start = time.time()\n",
    "last_time = start\n",
    "for i in range(n):\n",
    "    example = next(shuffled)\n",
    "\n",
    "    query = example[\"query\"]\n",
    "    prediction =  example['answers'][0]\n",
    "    example_id = dname + example[\"query_type\"] + str(example[\"query_id\"])\n",
    "\n",
    "    context_id = example[\"passages\"][\"is_selected\"].index(1)\n",
    "    context = example[\"passages\"][\"passage_text\"][context_id]\n",
    "\n",
    "    examples = make_examples(query, prediction, dname, example_id=example_id, context=context, k=k, retrieval=True, task=\"qa\", domain=\"openqa\")\n",
    "    \n",
    "    save_examples(i, start, last_time, examples, dname)\n",
    "\n",
    "itrf_dataset_buffer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deprecated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
